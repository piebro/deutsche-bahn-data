name: Fetch and Upload Deutsche Bahn Data
on:
  schedule:
    # Run every 6 hours at 3am, 9am, 3pm, 9pm UTC
    - cron: '0 3,9,15,21 * * *'
  workflow_dispatch:

jobs:
  fetch-and-upload:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Setup uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          uv sync --python 3.13

      - name: Fetch Deutsche Bahn data
        env:
          DB_API_KEY: ${{ secrets.DB_API_KEY }}
          DB_CLIENT_ID: ${{ secrets.DB_CLIENT_ID }}
        run: |
          # Create .env file with API key
          echo "DB_API_KEY=$DB_API_KEY" > .env

          # Calculate hours: current hour -3 to +2 (6 hour window)
          CURRENT_HOUR=$(date -u +"%H")
          HOURS=""
          for i in {-3..2}; do
            HOUR=$(( (10#$CURRENT_HOUR + i + 24) % 24 ))
            if [ -z "$HOURS" ]; then
              HOURS="$HOUR"
            else
              HOURS="$HOURS,$HOUR"
            fi
          done

          echo "Fetching data for hours: $HOURS"

          # Fetch data for the 6-hour window
          uv run python scripts/fetch_eva_plan_and_change.py --categories 1,2,3,4,5,6,7 --hours "$HOURS"

      - name: Upload data to Hugging Face
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          bash scripts/upload_data_to_huggingface.sh
